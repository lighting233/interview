## http2.0

### 一、http1.1对比http1.0有哪些优化
1. **缓存处理**：增加了缓存字段
2. **带宽优化及网络连接的使用**：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接
3. **状态码**：在HTTP1.1中新增了24个错误状态响应码
4. **Host头处理**：随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）
5. **长连接**：在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive

### 二、http1.1存在哪些问题？
1. http1.1 的**报文主体压缩**，（压缩后的数据都是二进制数据，通常在传输过程中保持原始的二进制形式）但**首部没有压缩**，每次大量的首部如 cookie 重复传输，增加开销
   1. 客户端请求压缩可以在请求头中通过 Accept-Encoding 字段 `Accept-Encoding: gzip, deflate`
   2. 服务器接收到客户端的请求后，会检查 Accept-Encoding 头部，并选择一种客户端支持的压缩算法对响应主体进行压缩，然后在响应头中标明所使用的压缩算法 `Content-Encoding: gzip`
   3. 压缩可以显著减少传输数据的大小，尤其是对大文本文件（如 HTML、CSS、JavaScript 等），从而提高加载速度并减少带宽使用
   4. 对非文本数据的影响：对于已经压缩过的数据（如 JPEG 图像、视频文件），再进行 HTTP 压缩通常没有太大意义，甚至可能导致文件变大
   5. 处理开销：压缩和解压缩都需要计算资源，如果服务器或客户端的资源有限，过度使用压缩可能导致性能问题。

2. **队头阻塞问题**
   1. 在 HTTP/1.1 中，同一条 TCP 连接是半双工的，即客户端在发送请求时必须等待服务器完全响应完毕才能发送下一个请求。如果前一个请求的响应还没有完全收到，后续的请求就会被阻塞，无法发送。
   2. 例如先请求了一个很大的 js 文件，后续想再请求一个很小的 css 文件，也要等到，大的传输完才能请求下一个
   3. 响应时丢包了，需要等待重传成功后才能进行下一个请求。

    #### 解决方案，雪碧图或域名分片技术
      1. 雪碧图和域名分片增加开发人员工作量。
      2. 同一个域名下持久连接数有限，连接太多可能造成 ddos 攻击。
      3. 虽然进行了域名分片，但 tcp 有慢启动，起始速度还是慢
      4. 虽然 http1.1 支持管线化连接，但是还是要按顺序发送和响应，其中一个阻塞，后边还是要等待，所以浏览器大部分没实现这个功能
      5. base64

3. **明文传输**，免费WiFi陷阱
4. **不支持服务端推送**

### 三、http2.0解决了哪些问题
1. **HTTP/2 的首部压缩**
   1. **静态表**（Static Table）：预定义了一些常见的 HTTP 首部字段及其常见值，这些字段可以用一个索引号来表示，从而减少传输的字节数。
   2. **动态表**（Dynamic Table）：在通信过程中，客户端和服务器可以建立一个动态表，用于存储已经传输过的首部字段及其值。新的首部字段可以引用动态表中的索引，从而减少重复的传输
   >例如，如果一个请求包含如下的 Cookie 字段：
   ```http
   Cookie: sessionId=abc123
   ```
   >在传统的 HTTP/1.1 中，每次请求都会重复发送整个 Cookie 字段及其值。而在 HTTP/2 中，第一次发送时，Cookie 字段和值会被存储到动态表中，后续请求只需发送其索引号，极大地减少了传输数据量
2. **二进制分帧**：在每个资源块前添加一个数据帧，它允许在单个 TCP 连接上通过交错排列块来多路传输多个资源。它还解决了第一个资源缓慢时的队头阻塞问题
   1. 头部帧（HEADERS frame）：包含流 id：stream id，后跟头信息，有 content-length
   2. 数据帧（DATA frame）：包含流 id：stream id，和一个数据块长度 content，后跟数据块内容

#### 流的权重与传输方式
如果我们再次用 1 和 2 来表示，我们会发现对于 HTTP/1.1，唯一的选项是11112222（我们称之为顺序的（sequential））。然而， HTTP/2 有更多的自由：

- 公平多路复用（例如两个渐进的 JPEGs）：12121212
- 加权多路复用（2是1的两倍）：22122122121
- 反向顺序调度（例如2是密钥服务器推送的资源）：22221111
- 部分调度（流1被中止且未完整发送）：112222
- 使用哪种方法是由 HTTP/2 中所谓的“优先级（prioritization）”系统驱动的，所选择的方法对Web 性能有很大的影响

3. **多路复用**：HTTP2建立一个TCP连接，一个连接上面可以有任意多个流（stream），消息分割成一个或多个帧在流里面传输。帧传输过去以后，再进行重组，形成一个完整的请求或响应
4. http2 **默认使用 TLS 加密**，因为都已经进行二进制分帧了
5. **支持服务端推送**

### 四、http2.0还存在哪些问题？
1. **TCP 队头阻塞**：HTTP/2 只解决了 HTTP 级别的队头阻塞，我们可以称之为“应用层”队头阻塞。然而，在典型的网络模型中，还需要考虑下面的其他层。http2基于tcp，tcp不知道报文帧的内容哪个和哪个是一起的，tcp按照自己的数据段来发送，数据丢失依旧得重传。
    #### 例子:
    例子是数据包1丢失，但是接收到2和3的情况。TCP将再次阻止数据包2和3，等待1。但是，我们可以看到，在HTTP/2级别，流2的数据（CSS文件）完全存在于数据包2和3中，不必等待数据包1的重新传输。浏览器本可以完美地解析/处理/使用 CSS 文件，但却被困在等待 JS 文件的重新传输.请记住，**TCP并不知道它正在承载 HTTP/2**，只知道它需要按顺序传递数据。
    #### 如果我们仍然有 TCP 队头阻塞，为什么还要使用HTTP/2 呢?
    主要原因是虽然数据包丢失确实发生在网络上，但还是比较少见的。特别是在有线网络中，包丢失率只有 0.01%。即使是在最差的蜂窝网络上，在现实中，您也很少看到丢包率高于2%。
    包丢失率为2%并不意味着每100个包中总是有2个包丢失（例如数据包 42 和 96）。实际上，可能更像是在总共500个包中丢失10个连续的包（例如数据包255到265）。这是因为数据包丢失通常是由网络路径中的路由器内存缓冲区暂时溢出引起的，这些缓冲区开始丢弃无法存储的数据包。
    **重要的是：**是的，TCP 队头阻塞是真实存在的，但是它对 Web 性能的影响要比HTTP/1.1 队头阻塞小得多，HTTP/1.1 队头阻塞几乎可以保证**每次**都会遇到它，而且它**也会受到 TCP 队头阻塞**的影响！
    #### 有些情况 http1.1 可能表现的比 http2 好
    都是单个链接时，情况和上边一样，所以 http1.1 经常开启多个连接。
    这使得 HTTP/1.1 不仅在一定程度上减轻了 HTTP 级别，而且减轻了 TCP 级别的队头阻塞。因此，在某些情况下，单个连接上的 HTTP/2 很难比6个连接上的 HTTP/1.1 快，甚至与 HTTP/1.1 一样快。这主要是由于 TCP 的“拥塞控制”（congestion control）机制。
2. **TCP 以及 TCP+TLS建立连接的延时**：
   1. 在建立TCP连接的时候，需要和服务器进行三次握手来确认连接成功，也就是说需要在消耗完**1.5个RTT**之后才能进行数据传输。
   2. 进行TLS连接，TLS有两个版本——TLS1.2和TLS1.3，每个版本建立连接所花的时间不同，大致是需要**1~2个RTT**。http1.1 + TLS/1.2 ：3+3=6次握手；http1.1 + TLS/1.3 ：3+2=5次握手
3. **服务端推送**：客户可能误点，但直接推送一堆资源过来，增加了很多缓存。可能存在 **DDOS 分对称攻击**，因为这里存在明显的**杠杆**