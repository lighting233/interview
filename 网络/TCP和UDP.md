[TOC]
# TCP 和 UDP

## 一、TCP 和 UDP对比
- UPD 无连接不可靠；支持单播，多播，广播；UDP 是面向应用报文的
- TCP 面向连接可靠（不会出现误码，丢失，重复，乱序）全双工；仅支持单播，即一对一的传输；TCP 是面向字节流的，这是他实现可靠传输，流量控制以及拥塞控制的基础
---
## 二、TCP传输控制协议
[b站讲解](https://www.bilibili.com/video/BV1c4411d7jb?p=58&vd_source=78435c3cefd4783245d9d16d09d19859)
[对应笔记](https://github.com/BloothOfYouth/Computer-Network-Notes/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%88%E8%BF%90%E8%BE%93%E5%B1%82%EF%BC%89.md)
网络层已经打通两台机器连接的基础，但通信是个机器里不同的进程通过端口号区分，进行连接的
---

### 新版本的 chrome 中同一域名下同时最多能建立几个 tcp 连接？
在现代浏览器中，包括最新版本的 Chrome，针对同一域名（也称为同一主机名）同时能够建立的 TCP 连接数是有限制的。这些限制是为了防止单个网站占用过多的网络资源，从而影响其他网站的性能。

对于 Chrome 浏览器，以下是一些常见的连接限制：

- **HTTP/1.1**：同一域名下最多可以建立 6 个并发的 TCP 连接。
- **HTTP/2**：HTTP/2 协议允许在单个 TCP 连接上进行多路复用（multiplexing），这意味着可以在一个连接上同时处理多个请求。因此，HTTP/2 通常只需要一个 TCP 连接来处理同一域名下的所有请求。

这些限制是由浏览器实现的，并且可能会根据浏览器版本和具体实现有所不同。以下是一个简要的总结：

- **HTTP/1.1**：6 个并发连接
- **HTTP/2**：1 个连接（多路复用）

需要注意的是，这些限制是针对同一域名的，并且不同的浏览器可能会有略微不同的实现，但大多数现代浏览器的行为是相似的。

### TCP首部

- **源端口号：16bit**客户端从49151~65535中随机选一个，例如发送 DNS 查询则封装 TCP 首部，源端口号：65535，目的端口号：53，DNS 服务器收到报文发现目的端口号为 53，则交给 DNS 查询进程
- **目的端口号：16bit**
  - UPD 协议：DNS 53
  - TCP 协议：SMTP 25，FTP 20/21,HTTP 80, HTTPS 443
- **序号 32bit** 取值 0-2^32^-1
- **确认号 32bit**
- **数据偏移** 占 4bit 并以 4字节为单位，指出了 tcp 报文首部长度
- **确认标志位**：URG 紧急标志位,ACK,PSH 尽快交付应用进程，不必等到缓存填满后交付,RST 用来复位 tcp 连接，表示连接出现了异常，必须释放连接，然后重新建立；也可用来拒绝一个非法报文，或拒绝打开一个 tcp 连接,SYN,FIN
- **窗口字段 16bit**：rwnd 拥塞窗口 cwnd，发送窗口 swnd，从接收窗口和拥塞窗口中取小者
- **校验和**：是否出现误码
- **紧急指针 16bit**
- **选项部分** 有时间戳等等，计算 RTT
- **填充**


首部最小 20 字节，最大 60 字节

### 流量控制 （针对双方的缓存空间）
重传计时器超时后，零窗口探测报文段会被重传
- 超时重传
- 探测报文（也有自己的定时重传）

#### 流量控制窗口和拥塞窗口两者取小值
### 拥塞控制 （针对网络承载能力）
慢开始和拥塞避免（**TCP Tahoe**）
1. **慢开始**：维护一个**慢开始门限** ssthresh；当 cwnd < ssthresh时使用慢开始算法；swnd = cwnd，传输轮次结束后cwnd指数级增长。cwnd > ssthresh时开始使用拥塞避免算法；指初始注入的报文段少，不是指 cwnd 增长速度慢。
2. **拥塞避免**：传输轮次结束后cwnd开始线性增长，发生传输失败，并且重传计时器超时时，判断网络很可能发生了拥塞，将ssthresh更新为当前 cwnd 值的一半，将 cwnd 值减小为 1，使用慢开始算法；当达到慢开始门限时，使用拥塞避免算法；并非指完全避免拥塞，是指控制 cwnd 为线性增长，比较不容易出现拥塞。

快重传和快恢复（**TCP Reno**）有时个别网络报文丢失并非网络发生堵塞，这导致发送方超时重传，误认为网络发生了拥塞，降低了传输效率。
3. **快重传**：采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失。
所谓快重传，就是使发送方尽快进行重传，而不是等超时重传计时器超时再重传。
- 要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认；
- 即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认。
- 发送方一旦收到3个连续的重复确认，就将相应的报文段立即重传，而不是等该报文段的超时重传计时器超时再重传。
- 对于个别丢失的报文段，发送方不会出现超时重传，也就不会误认为出现了拥塞（进而降低拥塞窗口cwnd为1）。使用快重传可以使整个网络的吞吐量提高约20％。
- 例如 3 号报文段发送时丢失，发送方又发送 4 号报文，接收方发现失序报文，会对 3 号进行重复确认
  
4. **快恢复**：发送方一旦收到3个重复确认，就知道现在只是丢失了个别的报文段。于是不启动慢开始算法，而执行快恢复算法；
- 发送方将慢开始门限ssthresh值和拥塞窗口cwnd值调整为当前窗口的一半；开始执行拥塞避免算法。
- 也有的快恢复实现是把快恢复开始时的拥塞窗口cwnd值再增大一些，即等于新的ssthresh + 3。既然发送方收到3个重复的确认，就表明有3个数据报文段已经离开了网络；这3个报文段不再消耗网络资源而是停留在接收方的接收缓存中；
可见现在网络中不是堆积了报文段而是减少了3个报文段。因此可以适当把拥塞窗口扩大些。

### [TCP超时重传时间选择](https://github.com/BloothOfYouth/Computer-Network-Notes/raw/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%AC5%E7%AB%A0%EF%BC%88%E8%BF%90%E8%BE%93%E5%B1%82%EF%BC%89.assets/image-20201022153518218.png)
- 如果超时重传时间RTO的值设置得比RTT0的值小很多，这会引起报文段不必要的重传，使网络负荷增大
- 如果超时重传时间RTO的值设置得远大于RTT0的值，这会使重传时间推迟的太长，使网络的空闲时间增大，降低传输效率
- 超时重传时间 RTO 应该略大于加权平均往返时间 TRRs

### TCP可靠传输的实现
TCP 基于字节为单位的滑动窗口来实现可靠传输
tcp 实现可靠有序传输的机制依靠两个方面
- 确认应答机制
- 超时重传机制
### TCP连接建立
解决三个问题
1. 使TCP双方能够确知对方的存在；
2. 使TCP双方能够协商一些参数（如最大窗口值、是否使用窗口扩大选项和时间戳选项以及服务质量等）；
3. 使TCP双方能够对运输实体资源（如缓存大小、连接表中的项目等）进行分配。

流程
1. 服务器和客户端都在CLOSED 关闭状态
2. 服务端首先创建传输控制块，进入LISTEN 监听状态，称为被动打开连接
3. 客户端创建传输控制块，发送TCP连接请求报文段，进入SYN-SENT 同步已发送状态，称为主动打开连接
   - TCP连接请求报文段首部中：
     - **同步位**SYN被设置为1，表明这是一个TCP连接请求报文段
     - 序号字段seq被设置了一个初始值x，作为TCP客户端进程所选择的初始序号 **请注意：TCP规定SYN被设置为1的报文段不能携带数据，但要消耗掉一个序号**
4. 服务端如果同意建立连接，发送TCP连接请求**确认**报文段，进入SYN-RCVD 同步已接收状态
   - TCP连接请求确认报文段首部中：
   - **同步位**SYN**同部位**和**确认位**ACK都设置为1，表明这是一个TCP连接请求确认报文段
   - 序号字段seq被设置了一个初始值y，作为TCP服务器进程所选择的初始序号，
   - 确认号字段ack的值被设置成了x+1，这是对TCP客户进程所选择的初始序号（seq）的确认 **请注意：这个报文段也不能携带数据，因为它是SYN被设置为1的报文段，但同样要消耗掉一个序号**

5. TCP客户进程收到TCP连接请求确认报文段后，还要向TCP服务器进程发送一个**普通**的TCP确认报文段，并进入 ESTABLISHED 连接已连接状态
   - 确认位ACK被设置为1，表明这是一个普通的TCP确认报文段
   - 序号字段seq被设置为x+1，这是因为TCP客户进程发送的第一个TCP报文段的序号为x，所以TCP客户进程发送的第二个报文段的序号为x+1
   - 确认号字段ack被设置为y+1，这是对TCP服务器进程所选择的初始序号的确认 **请注意：TCP规定普通的TCP确认报文段可以携带数据，但如果不携带数据，则不消耗序号**

#### 能否两次握手，最后一次普通确认报文能否省略？

### TCP链接释放
1. 双方都在ESTABLISHED 连接已连接状态
2. 客户端发送TCP连接释放报文段，并进入FIN-WAIT-1 终止等待1状态
   - TCP连接释放报文段首部中：
     - 终止位FIN和确认为ACK的值都被设置为1，表明这是一个TCP连接释放报文段，同时也对之前收到的报文段进行确认 **请注意：TCP规定终止位FIN等于1的报文段即使不携带数据，也要消耗掉一个序号**
     - 序号seq字段的值设置为u，它等于TCP客户进程之前已传送过的数据的最后一个字节的序号加1
     - 确认号ack字段的值设置为v，它等于TCP客户进程之前已收到的、数据的最后一个字节的序号加1
3. TCP服务器进程收到TCP连接释放报文段后，会发送一个**普通**的TCP确认报文段并进入CLOSE-WAIT 关闭等待状态
   - 普通的TCP确认报文段首部中：
     - 确认位ACK的值被设置为1，表明这是一个普通的TCP确认报文段
     - 序号seq字段的值设置为v，**普通确认报文不携带数据则不消耗序号**
     - 确认号ack字段的值设置为u+1，这是对TCP连接释放报文段的确认
4. TCP客户进程到TCP服务器进程这个方向的连接就释放了，客户端进入FIN-WAIT-2 半连接状态，等待TCP服务器进程发出的TCP连接释放报文段；但是如果TCP服务器进程还有数据要发送，TCP客户进程仍要接收，也就是说从TCP服务器进程到TCP客户进程这个方向的连接并未关闭
5. TCP服务器进程发送TCP连接释放报文段并进入LAST-ACK最后确认状态
   - 连接释放报文首部：
     - 终止位FIN和确认位ACK的值都被设置为1，表明这是一个TCP连接释放报文段，同时也对之前收到的报文段进行确认 
     - 序号seq字段的值为w，这是因为在半关闭状态下，TCP服务器进程可能又发送
     - 确认号ack字段的值为u+1，这是对之前收到的客户端TCP连接释放报文段的重复确认
6. TCP客户进程收到服务器TCP连接释放报文段后，必须针对该报文段发送**普通**的TCP确认报文段，之后进入 TIME-WAIT时间等待状态
   - 普通的TCP确认报文首部：
     - 确认为ACK的值被设置为1，表明这是一个普通的TCP确认报文段
     - 序号seq字段的值设置为u+1，这是因为TCP客户进程之前发送的TCP连接释放报文段虽然不携带数据，但要消耗掉一个序号
     - 确认号ack字段的值设置为w+1，这是对所收到的TCP连接释放报文段的确认

7. TCP服务器进程收到该报文段后就进入关闭状态，而TCP客户进程还要进过2MSL后才能进入关闭状态
#### TCP客户进程在发送完最后一个确认报文后，为什么不直接进入关闭状态？而是要进入时间等待状态？
因为时间等待状态以及处于该状态2MSL时长，可以确保TCP服务器进程可以收到最后一个TCP确认报文段而进入关闭状态，
客户端最后一次的确认请求如果丢失，然后客户端直接关闭，则服务端一直超时重传。
客户端等到时，再次收到服务端的释放链接请求，则知道自己刚才发送的确认报文丢失了
### TCP保活计时器的作用
- TCP双方已经建立了连接，后来，TCP客户进程所在的主机突然出现了故障
- TCP服务器进程以后就不能再收到TCP客户进程发来的数据
- 因此，应当有措施使TCP服务器进程不要再白白等待下去

实现：
- TCP服务器进程每收到一次TCP客户进程的数据，就重新设置并启动保活计时器（2小时定时）。
- 若保活计时器定时周期内未收到TCP客户进程发来的数据，则当保活计时器到时后，TCP服务器进程就向TCP客户进程发送一个探测报文段，以后则每隔75秒钟发送一次。若一连发送10个探测报文段后仍无TCP客户进程的响应，TCP服务器进程就认为TCP客户进程所在主机出了故障，接着就关闭这个连接。
- **注意**：往往这个时间太久了，我们熟知的很多组件都没有开启 keepalive 特性，而是选择在应用层做心跳机制。

---
## 三、UDP用户数据协议
题外话：UDP协议想要保证可靠，靠的就是程序员在应用层仿照 确认应答和超时重传 就好了
### UDP首部
- 源端口
- 目的端口
- 长度
- 检验和

四个字段，每个字段 2 字节一共 8 字节

---
## 四、tcp粘包问题

TCP 粘包（或称为粘包问题）是指在 TCP 协议中，数据包的边界可能会被“粘在一起”，从而导致接收方无法准确区分消息的边界。这个问题是由 TCP 协议的特性和网络数据传输的方式造成的。理解这一点需要对 TCP 的工作机制有一定的了解。

### 什么是 TCP 粘包？

在 TCP（传输控制协议）中，数据以字节流的形式进行传输，而不是以消息为单位。由于 TCP 是一个面向连接、流式的协议，它不保证数据包的边界。因此，当发送方将多个消息发送到网络时，这些消息可能在网络中被合并成一个更大的数据块到达接收方，这就产生了粘包问题。反之，接收方也可能将一个大的数据块拆分为多个数据块接收到，这种情况叫做“拆包”。

- 程序需要发送的数据大小和TCP报文段能发送**MSS** （Maximum Segment Size，最大报文长度）是不一样的，大于MSS时，而需要把程序数据拆分为多个TCP报文段，称之为拆包；小于时，则会考虑合并多个程序数据为一个TCP报文段，则是粘包；
**其中MSS = TCP报文段长度-TCP首部长度**
网上很多说是TCP粘包，包括面试题中也有TCP粘包，但TCP中没有包这个概念，包是应用层的数据包，TCP是以字节流进行发送的，接收方TCP也是按顺序收到发送方的字节流，之所以会有粘包是因为我们要发送应用层的两个数据包，一个登录数据包data1，一个注销数据包data2，由于TCP流的特性，在接收方会出现以下几种情况：
1. 先接收到data1，然后接收到data2
2. 一次性接收到data1和data2的全部数据
3. 先接收到data1的全部数据和data2的部分数据，然后接收到了data2的余下数据
4. 先接收到data1的部分数据，然以后接收到data1余下积data2全部数据
对于1这种情况是我们希望见到的，两个数据包分开，而对于2，3，4的情况都是大家s说的粘包问题，这时就需要对收到的数据

### 如何解决 TCP 粘包问题？

- TCP 粘包问题产生的原因主要有以下几个方面：

1. **流式传输**：
   - TCP 是流式协议，它不会区分消息的边界。它只是保证数据的可靠性和顺序，而不关心数据的结构和边界。
   - 发送的数据被当作一个连续的字节流发送到接收方，接收方收到的数据也同样是字节流，数据的边界在传输过程中可能会被丢失。

2. **数据合并**：
   - 如果发送方连续发送多个小的数据块（如多个 HTTP 请求），这些数据块在网络中可能被合并成一个大的数据块一起到达接收方。
   - 由于网络的缓冲区和 TCP 的流量控制机制，发送的数据可能会被组合在一起再发送，导致接收方收到的数据流中包含了多个逻辑消息。

3. **网络缓冲区**：
   - 在发送方和接收方，网络设备和操作系统通常使用缓冲区来存储数据。数据在这些缓冲区中可能会被合并或拆分，从而影响数据的边界。
   - 当缓冲区被填满时，发送的数据可能会被分成多个 TCP 包进行发送，而这些 TCP 包在网络中可能会被重新组装成一个数据流。

- 造成TCP粘包的原因
- （1） 发送方原因
TCP默认使用**Nagle**算法（主要作用：减少网络中报文段的数量），而Magle算法主要做两件事：
1 只有上一个分组得到确认，才会发送下一个分组
2 收集多个小分组，在一个确认到来时一起发送
Nagle算法造成了发送方可能会出现粘包问题
- （2） 接收方原因
TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

### 如何解决 TCP 粘包问题？

解决 TCP 粘包和拆包问题通常需要在应用层进行一些处理。常见的解决方案包括：

1. **固定长度消息**：
   - 发送的数据块长度固定，接收方知道每个数据块的确切长度，从而能够准确解析消息边界。

2. **分隔符**：
   - 在消息中添加特殊的分隔符（例如，换行符、特殊字符等），接收方通过分隔符来分割消息。

3. **长度前缀**：
   - 在每个消息前面加上一个固定长度的头部，头部包含消息的长度信息。接收方可以先读取头部，然后根据长度信息读取完整的消息。

4. **应用层协议**：
   - 定义一个应用层协议，用于标识消息的边界和格式。例如，HTTP 协议中通过内容长度（Content-Length）头字段来指定消息的长度。


#### redis resp协议怎么解决
特定分隔符法在消息协议足够简单的场景下比较高效，Redis 在通信过程中采用的就是换行分隔符。
Redis 2.0 以后的通信统一为 RESP 协议 （Redis Serialization Protocol）
RESP是一个二进制安全的文本协议，工作于 TCP 协议上。RESP以行作为单位，客户端和服务器发送的命令或数据一律以 \r\n（CRLF）作为换行符。
#### http 解决
比如http协议，协议本身有header和body,header里面有Content-Length指定了body大小，接收方就知道接收多少字节后一个数据包的内容结束，就不会出现粘包问题在可以知道报文长度的情况下，可以使用Content-length，如果不知道则可以使用
HTTP/1.1中的Transfer-Encoding:chunked分块传输，chunked由数据长度（16进制）＋分块数据组成，数据长度为0结束。

### 示例

假设你有一个简单的协议，每条消息的格式如下：
```
[长度][内容]
```
- **长度** 是一个固定长度的字段，表示消息内容的字节数。
- **内容** 是实际的消息数据。

在这种协议下，发送方会首先发送消息的长度，然后发送实际的消息内容。接收方根据长度信息读取指定数量的字节，从而解析出完整的消息。

### 总结

- **TCP 粘包** 是因为 TCP 是流式协议，它将数据当作连续的字节流来处理，导致消息的边界可能在网络传输过程中丢失。
- **产生原因** 包括流式传输、数据合并和网络缓冲区的处理方式。
- **解决方法** 包括使用固定长度消息、分隔符、长度前缀或者设计合适的应用层协议。

通过这些方法，应用层可以有效地处理 TCP 粘包问题，确保数据的正确性和完整性。


#### UDP会不会粘包
- 不会
- TCP回了保证可靠传输并减少额外开销，采用基于流的传输，因此会出现粘包问题，而UDP则是面向消息传输的，接收方一次只接收一条独立的信息，所以不存在粘包问题比如我现在有三条数据包，大小分别是2k，4k,6k，如果使用UDP协议发送，不管接收方的缓存区有多大，都需要经历三次接收动作来分别接收三个数据包，而使用TCP协议，我们只需要把缓冲区大小设置为12k以上，我们就能一次把所有数据包都接收下来，只需要一次动作。因此这几个数据包时连在一起的

---
#### TCP粘包问题，如果设置长度而当前没收到这么多怎么办？
当处理 TCP 粘包问题时，如果应用层协议中包含长度前缀，接收方必须能够正确处理部分数据的情况，即当数据流中接收的内容少于预期长度时。这个问题常常在网络传输中发生，因为数据传输可能会因为各种原因（如网络延迟、带宽限制等）而不完整。处理这种情况的方法包括以下几个步骤：

### 1. **分块接收和缓存**

接收方需要实现一个机制来处理接收到的部分数据。通常的方法是：

- **缓存数据**：当接收到的数据块小于预期的长度时，先将已接收到的数据缓存到内存中，并等待剩余的数据到达。
- **拼接数据**：当新的数据到达时，将其追加到缓存中，然后检查缓存中的数据是否足够。只有当缓存中的数据总量达到或超过预期长度时，才解析出完整的消息。

**示例代码**：

假设你的消息格式是 `[长度][内容]`，其中 `[长度]` 是一个固定长度的字段，表示 `内容` 的字节数。

```python
import socket
import struct

def receive_message(sock):
    buffer = b''
    while True:
        # 读取数据到缓存
        data = sock.recv(4096)
        if not data:
            break
        buffer += data
        
        # 如果缓存中数据不足以确定长度，就继续等待
        if len(buffer) < 4:
            continue
        
        # 提取消息长度（假设长度字段是4字节）
        message_length = struct.unpack('!I', buffer[:4])[0]
        
        # 如果缓存数据不足以包含完整的消息，就继续等待
        if len(buffer) < 4 + message_length:
            continue
        
        # 提取完整的消息内容
        message = buffer[4:4 + message_length]
        buffer = buffer[4 + message_length:]
        return message

# 使用示例
# server_socket = socket.create_server(('localhost', 12345))
# client_socket, _ = server_socket.accept()
# message = receive_message(client_socket)
# print(message)
```

### 2. **超时处理**

接收方可以设置一个超时机制，以避免长时间等待数据。例如，如果在一定时间内没有收到预期的数据量，可以返回错误或超时提示。超时处理有助于防止接收方在等待数据时被无限期阻塞。

**示例代码**：

```python
import socket
import select
import struct

def receive_message(sock, timeout=5.0):
    buffer = b''
    end_time = time.time() + timeout
    while True:
        # 计算剩余时间
        remaining_time = end_time - time.time()
        if remaining_time <= 0:
            raise TimeoutError("Timeout while waiting for data")
        
        # 设置超时
        readable, _, _ = select.select([sock], [], [], remaining_time)
        if not readable:
            raise TimeoutError("Timeout while waiting for data")
        
        # 读取数据到缓存
        data = sock.recv(4096)
        if not data:
            break
        buffer += data
        
        # 如果缓存中数据不足以确定长度，就继续等待
        if len(buffer) < 4:
            continue
        
        # 提取消息长度（假设长度字段是4字节）
        message_length = struct.unpack('!I', buffer[:4])[0]
        
        # 如果缓存数据不足以包含完整的消息，就继续等待
        if len(buffer) < 4 + message_length:
            continue
        
        # 提取完整的消息内容
        message = buffer[4:4 + message_length]
        buffer = buffer[4 + message_length:]
        return message
```

### 3. **协议设计**

在协议设计中，考虑如何处理数据丢失或部分接收的情况是很重要的。例如：

- **消息确认机制**：设计一个机制来确认消息的接收和处理状态。
- **数据完整性校验**：使用校验和（如 CRC）来确保数据的完整性，如果接收到的消息不完整或出现错误，可以请求重传。

### 4. **错误处理**

当接收到的数据不完整或解析失败时，应处理这些错误并进行适当的响应：

- **重试机制**：如果数据不完整，可以尝试重新接收数据。
- **错误报告**：报告接收到的数据有问题，以便在应用层进行进一步处理或通知用户。

### 总结

- **分块接收**：缓存部分接收到的数据，等待剩余数据到达，直到接收到完整的消息。
- **超时处理**：设置超时机制以避免无限期等待数据。
- **协议设计**：设计协议时考虑如何处理数据丢失或部分接收的情况。
- **错误处理**：处理接收到的数据不完整或解析失败的情况。

通过这些方法，你可以有效地处理 TCP 粘包问题，并确保数据的完整性和可靠性。

---

#### SYN报文什么下会被丟弃？
- 第一个：TCP 两个队列满了（半连接队列和全连接队列），造成SYN报文被丟弃
- 第二个：开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN报文被丟弃

#### tcp如何提高传输效率
1. 发送方的发送量（也可以理解为发送速率）滑动窗口
2. 接收方的接收能力（对方是否能承受大的数据量）
   - 流量控制机制：通过接收方的接收能力来控制发送方发送的数据量
   - 延时应答机制：接收方通过延时一小会，想要给发送方回复一个接收能力（更大的窗口大小）
3. 网络的转发能力（网络是否能转发大的数据量）拥塞机制